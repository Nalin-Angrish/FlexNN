<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>FlexNN: FlexNN::Layer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">FlexNN<span id="projectnumber">&#160;1</span>
   </div>
   <div id="projectbrief">Fully connected neural network built from scratch with flexible n-layer design and multiple activations.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classFlexNN_1_1Layer.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classFlexNN_1_1Layer-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">FlexNN::Layer Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Represents a single layer in a neural network.  
 <a href="classFlexNN_1_1Layer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="Layer_8h_source.html">Layer.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ad47b22581c698822902c361816dc487e" id="r_ad47b22581c698822902c361816dc487e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classFlexNN_1_1Layer.html#ad47b22581c698822902c361816dc487e">Layer</a> (int inputSize, int outputSize, const std::string &amp;activationFunction=&quot;relu&quot;)</td></tr>
<tr class="memdesc:ad47b22581c698822902c361816dc487e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor for the <a class="el" href="classFlexNN_1_1Layer.html" title="Represents a single layer in a neural network.">Layer</a> class.  <br /></td></tr>
<tr class="separator:ad47b22581c698822902c361816dc487e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79373920227625f5e225ce49df533e14" id="r_a79373920227625f5e225ce49df533e14"><td class="memItemLeft" align="right" valign="top">Eigen::MatrixXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classFlexNN_1_1Layer.html#a79373920227625f5e225ce49df533e14">getWeights</a> () const</td></tr>
<tr class="memdesc:a79373920227625f5e225ce49df533e14"><td class="mdescLeft">&#160;</td><td class="mdescRight">Getters for weights.  <br /></td></tr>
<tr class="separator:a79373920227625f5e225ce49df533e14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af486a1cfedf6288ab8afa2c163589f96" id="r_af486a1cfedf6288ab8afa2c163589f96"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classFlexNN_1_1Layer.html#af486a1cfedf6288ab8afa2c163589f96">getBiases</a> () const</td></tr>
<tr class="memdesc:af486a1cfedf6288ab8afa2c163589f96"><td class="mdescLeft">&#160;</td><td class="mdescRight">Getters for biases.  <br /></td></tr>
<tr class="separator:af486a1cfedf6288ab8afa2c163589f96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5664082dbfb98de7cb3a1233f3795c11" id="r_a5664082dbfb98de7cb3a1233f3795c11"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classFlexNN_1_1Layer.html#a5664082dbfb98de7cb3a1233f3795c11">updateWeights</a> (const Eigen::MatrixXd &amp;dW, const Eigen::VectorXd &amp;db, double learningRate)</td></tr>
<tr class="memdesc:a5664082dbfb98de7cb3a1233f3795c11"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update weights and biases.  <br /></td></tr>
<tr class="separator:a5664082dbfb98de7cb3a1233f3795c11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0837c21dffec4cb2df94a48b5932630b" id="r_a0837c21dffec4cb2df94a48b5932630b"><td class="memItemLeft" align="right" valign="top">std::pair&lt; Eigen::MatrixXd, Eigen::MatrixXd &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classFlexNN_1_1Layer.html#a0837c21dffec4cb2df94a48b5932630b">forward</a> (const Eigen::MatrixXd &amp;input)</td></tr>
<tr class="memdesc:a0837c21dffec4cb2df94a48b5932630b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward pass through the layer.  <br /></td></tr>
<tr class="separator:a0837c21dffec4cb2df94a48b5932630b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a531b2be03b2995390e2b9a0288a2cdd3" id="r_a531b2be03b2995390e2b9a0288a2cdd3"><td class="memItemLeft" align="right" valign="top">Eigen::MatrixXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classFlexNN_1_1Layer.html#a531b2be03b2995390e2b9a0288a2cdd3">backward</a> (const Eigen::MatrixXd &amp;nextW, const Eigen::MatrixXd &amp;nextdZ, const Eigen::MatrixXd &amp;currZ)</td></tr>
<tr class="memdesc:a531b2be03b2995390e2b9a0288a2cdd3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Backward pass through the layer.  <br /></td></tr>
<tr class="separator:a531b2be03b2995390e2b9a0288a2cdd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Represents a single layer in a neural network. </p>
<p>The <a class="el" href="classFlexNN_1_1Layer.html" title="Represents a single layer in a neural network.">Layer</a> class encapsulates the properties and methods required for a neural network layer, including weights, biases, forward and backward passes, and weight updates.</p>
<p>This class is designed to be flexible and can be used with different activation functions. It supports both relu and softmax activation functions by default, but can be extended to include others. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ad47b22581c698822902c361816dc487e" name="ad47b22581c698822902c361816dc487e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad47b22581c698822902c361816dc487e">&#9670;&#160;</a></span>Layer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">FlexNN::Layer::Layer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>inputSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>outputSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>activationFunction</em> = <code>&quot;relu&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructor for the <a class="el" href="classFlexNN_1_1Layer.html" title="Represents a single layer in a neural network.">Layer</a> class. </p>
<p>Initializes the layer with random weights and biases.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputSize</td><td>The size of the input to this layer. </td></tr>
    <tr><td class="paramname">outputSize</td><td>The size of the output from this layer (also the number of neurons of this layer). </td></tr>
    <tr><td class="paramname">activationFunction</td><td>The activation function to be used in this layer (default is "relu").</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>If this is the last layer, the activation function should be "softmax". </dd></dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a531b2be03b2995390e2b9a0288a2cdd3" name="a531b2be03b2995390e2b9a0288a2cdd3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a531b2be03b2995390e2b9a0288a2cdd3">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::MatrixXd FlexNN::Layer::backward </td>
          <td>(</td>
          <td class="paramtype">const Eigen::MatrixXd &amp;&#160;</td>
          <td class="paramname"><em>nextW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Eigen::MatrixXd &amp;&#160;</td>
          <td class="paramname"><em>nextdZ</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Eigen::MatrixXd &amp;&#160;</td>
          <td class="paramname"><em>currZ</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Backward pass through the layer. </p>
<p>This method computes the gradient of the loss with respect to the inputs of this layer given the gradients from the next layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nextW</td><td>The weights of the next layer. </td></tr>
    <tr><td class="paramname">nextdZ</td><td>The gradients from the next layer. </td></tr>
    <tr><td class="paramname">currZ</td><td>The linear output (Z) of this layer. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The gradient of the loss with respect to the inputs of this layer (dZ). </dd></dl>

</div>
</div>
<a id="a0837c21dffec4cb2df94a48b5932630b" name="a0837c21dffec4cb2df94a48b5932630b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0837c21dffec4cb2df94a48b5932630b">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt; Eigen::MatrixXd, Eigen::MatrixXd &gt; FlexNN::Layer::forward </td>
          <td>(</td>
          <td class="paramtype">const Eigen::MatrixXd &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Forward pass through the layer. </p>
<p>This method computes the output of the layer given an input matrix. It applies the activation function to the linear combination of inputs and weights.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input data for the forward pass. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A pair containing the linear output (Z) and the activated output (A). </dd></dl>

</div>
</div>
<a id="af486a1cfedf6288ab8afa2c163589f96" name="af486a1cfedf6288ab8afa2c163589f96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af486a1cfedf6288ab8afa2c163589f96">&#9670;&#160;</a></span>getBiases()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd FlexNN::Layer::getBiases </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Getters for biases. </p>
<p>These methods return the biases of the layer.</p>
<dl class="section return"><dt>Returns</dt><dd>Eigen::VectorXd The biases of the layer. </dd></dl>

</div>
</div>
<a id="a79373920227625f5e225ce49df533e14" name="a79373920227625f5e225ce49df533e14"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79373920227625f5e225ce49df533e14">&#9670;&#160;</a></span>getWeights()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::MatrixXd FlexNN::Layer::getWeights </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Getters for weights. </p>
<p>These methods return the weights of the layer.</p>
<dl class="section return"><dt>Returns</dt><dd>Eigen::MatrixXd The weights of the layer. </dd></dl>

</div>
</div>
<a id="a5664082dbfb98de7cb3a1233f3795c11" name="a5664082dbfb98de7cb3a1233f3795c11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5664082dbfb98de7cb3a1233f3795c11">&#9670;&#160;</a></span>updateWeights()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void FlexNN::Layer::updateWeights </td>
          <td>(</td>
          <td class="paramtype">const Eigen::MatrixXd &amp;&#160;</td>
          <td class="paramname"><em>dW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Eigen::VectorXd &amp;&#160;</td>
          <td class="paramname"><em>db</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learningRate</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Update weights and biases. </p>
<p>This method updates the weights and biases of the layer using the provided gradients and a specified learning rate.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dW</td><td>The gradient of the weights. </td></tr>
    <tr><td class="paramname">db</td><td>The gradient of the biases. </td></tr>
    <tr><td class="paramname">learningRate</td><td>The learning rate for updating the weights and biases. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/<a class="el" href="Layer_8h_source.html">Layer.h</a></li>
<li>lib/<a class="el" href="Layer_8cpp.html">Layer.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceFlexNN.html">FlexNN</a></li><li class="navelem"><a class="el" href="classFlexNN_1_1Layer.html">Layer</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
